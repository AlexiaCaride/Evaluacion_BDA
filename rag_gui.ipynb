{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/miniconda3/envs/rag/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "2024 G20 Rio de Janeiro summit - Wikipedia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Jump to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      "\n",
      "\n",
      "\t\tNavigation\n",
      "\t\n",
      "\n",
      "\n",
      "Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tContribute\n",
      "\t\n",
      "\n",
      "\n",
      "HelpLearn to editCommunity portalRecent changesUpload file\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Appearance\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donate\n",
      "\n",
      "Create account\n",
      "\n",
      "Log in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Personal tools\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donate Create account Log in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tPages for logged out editors learn more\n",
      "\n",
      "\n",
      "\n",
      "ContributionsTalk\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Contents\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(Top)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Presidency\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "Agenda priorities\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle Agenda priorities subsection\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2.1\n",
      "G20 Social\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "Treaty against hunger and poverty\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "Preparations\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "Issues\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle Issues subsection\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5.1\n",
      "Russia and Ukraine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5.2\n",
      "Other issues\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "Participating leaders\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "7\n",
      "Invited guests\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "8\n",
      "Participating in\n",
      "Number of chunks: 35\n",
      "Documents added to the vector store.\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What is the title of the page?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21097/3664582976.py:63: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain.run(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The title of the page is \"2024 G20 Rio de Janeiro summit\".\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import gradio as gr\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "def extract_text_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    page_text = soup.get_text()\n",
    "    print(page_text[:1000]) \n",
    "    return page_text\n",
    "\n",
    "def split_text(text, chunk_size=500):\n",
    "    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "\n",
    "def create_qa_chain():\n",
    "    # LLM y otros modelos\n",
    "    llm = OllamaLLM(model=\"llama3.2\", server_url=\"http://localhost:11434\") \n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = Chroma(persist_directory=\"./vectorstore\", embedding_function=embedding_model)\n",
    "\n",
    "    # URL de Wikipedia (puedes modificarla si lo deseas)\n",
    "    url = \"https://en.wikipedia.org/wiki/2024_G20_Rio_de_Janeiro_summit\"\n",
    "\n",
    "    \n",
    "    # Extraer y procesar el contenido\n",
    "    page_content = extract_text_from_url(url)\n",
    "    chunks = split_text(page_content)\n",
    "    print(f\"Number of chunks: {len(chunks)}\")\n",
    "\n",
    "    documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "    vectorstore.add_documents(documents)\n",
    "    print(\"Documents added to the vector store.\")\n",
    "\n",
    "    # Crear el prompt de la cadena de pregunta-respuesta\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        template=\"Use the context below to answer the user's question:\\n\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "    )\n",
    "\n",
    "    # Crear un retriever\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    # Crear la cadena de QA\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "    \n",
    "    return qa_chain\n",
    "\n",
    "# Crear la cadena de QA al inicio\n",
    "qa_chain = create_qa_chain()\n",
    "\n",
    "def answer_question(question):\n",
    "    print(f\"Processing question: {question}\")  # Para ver la pregunta procesada\n",
    "    result = qa_chain.run(question)\n",
    "    print(f\"Answer: {result}\")  # Ver la respuesta generada\n",
    "    return result\n",
    "\n",
    "\n",
    "# Interfaz Gradio\n",
    "iface = gr.Interface(fn=answer_question, \n",
    "                     inputs=\"text\", \n",
    "                     outputs=\"text\", \n",
    "                     live=True, \n",
    "                     title=\"Wikipedia QA\",\n",
    "                     description=\"Pregúntame sobre la página de Wikipedia de el G20 de Brasil 2024.\")\n",
    "\n",
    "# Ejecutar la interfaz Gradio\n",
    "iface.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version MongloAtlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/miniconda3/envs/rag/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_21061/2828311738.py:23: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21061/2828311738.py:53: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain.run(pregunta)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.chains import RetrievalQA\n",
    "from pymongo import MongoClient\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "import gradio as gr\n",
    "\n",
    "# Conexión a MongoDB Atlas\n",
    "MONGODB_ATLAS_CLUSTER_URI = \"mongodb+srv://usuarioMongoAltas:contrasenha@cluster0.xmaru.mongodb.net/\"\n",
    "client = MongoClient(MONGODB_ATLAS_CLUSTER_URI)\n",
    "\n",
    "DB_NAME = \"vectorstore\"  # Cambia este valor al nombre de tu base de datos\n",
    "COLLECTION_NAME = \"paginaweb\"  # Cambia este valor al nombre de tu colección\n",
    "ATLAS_VECTOR_SEARCH_INDEX_NAME = \"g20_summit_index\"\n",
    "\n",
    "# Referencia a la colección de MongoDB\n",
    "MONGODB_COLLECTION = client[DB_NAME][COLLECTION_NAME]\n",
    "\n",
    "# Inicializa los embeddings de HuggingFace\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Configuración de MongoDB Atlas Vector Search\n",
    "vector_store = MongoDBAtlasVectorSearch(\n",
    "    collection=MONGODB_COLLECTION,\n",
    "    embedding=embeddings,\n",
    "    index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",
    "    relevance_score_fn=\"cosine\",  # Usamos la similitud del coseno para la recuperación\n",
    ")\n",
    "\n",
    "# Modelo LLM\n",
    "llm = OllamaLLM(model=\"llama3.2\", server_url=\"http://localhost:11434\")\n",
    "\n",
    "# Crear el prompt para la cadena de preguntas y respuestas\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template=\"Use the context below to answer the user's question:\\n\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    ")\n",
    "\n",
    "# Función para recuperar documentos desde MongoDB usando el vector store\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Crear la cadena de preguntas y respuestas\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "# Función para responder preguntas basadas en el contenido de MongoDB\n",
    "def responder_pregunta(pregunta):\n",
    "    response = qa_chain.run(pregunta)\n",
    "    return response\n",
    "\n",
    "# Crear la interfaz de usuario de Gradio\n",
    "interface = gr.Interface(\n",
    "    fn=responder_pregunta,                # Función que maneja la lógica\n",
    "    inputs=\"text\",                         # Tipo de entrada (texto)\n",
    "    outputs=\"text\",                        # Tipo de salida (texto)\n",
    "    live=True,                             # Activar respuesta en vivo\n",
    "    title=\"Sistema de Respuestas G20\",     # Título de la interfaz\n",
    "    description=\"Introduce una pregunta sobre el G20 Summit 2024 para obtener información de la página web.\"\n",
    ")\n",
    "\n",
    "# Ejecutar la interfaz\n",
    "interface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
